## OpenMP 
### 1. 共享内存平台和并行基础
共享内存平台允许多个线程并发执行，并共享一套全局变量。线程也有自己的局部私有变量。线程之间通过共享变量进行隐式通信，并通过同步机制进行显式协调。共享内存机器通常规模较小（例如，大型机约100个核心），因此需要粗粒度并行。多线程技术用于共享内存编程，其中OpenMP通过编译器指令和子句简化了并行化过程，而Pthread则需要显式创建和同步线程。 

#### 1.1. 线程基础 
- 一个进程包含多个线程。
- 进程中的线程共享相同的地址空间和进程状态，这大大降低了上下文切换的成本。
- 线程并发运行，并通过对共享地址空间中相同位置的读/写进行交互。
- 无法假定任何执行顺序；任何此类顺序都必须使用同步机制建立。
- 存在死锁、饥饿和性能问题。
- 所有通用现代操作系统都支持线程。
#### 1.2. 共享内存平台编程 
- 全局变量由所有线程共享，这使得算法设计看起来更容易，因为数据不需要移动。
- 数据划分和数据局部性至关重要，但线程之间的数据分布通常是隐式的，因为需要考虑ILP（指令级并行）、内存层次结构和缓存效应。
- 显式同步：在共享内存机器中，全局数据由多个线程共享。同步必须用于保护对共享数据的访问以防止竞态条件，并施加顺序约束。还需要防止应用同步时可能出现的死锁。

#### 1.3. 竞态条件 (Race Condition) 
- 当多个线程读写共享数据项时，最终结果变得不可预测，输出取决于哪个线程最后完成。
- 例如，两个线程同时对一个共享计数器进行递增和递减操作，如果不同步，计数器的最终值可能是4、5或6（假设初始值为5）。这是因为高层次的递增/递减操作会涉及多个机器指令（读-修改-写），这些指令在执行过程中可能交错，导致结果不确定性。
- 为了防止竞态条件，需要确保一个递增（或递减）操作在另一个操作进行之前- 完成，即实现互斥。
### 2. 矩阵乘法示例 (Example: Matrix Multiplication)
对于矩阵乘法，可以绘制任务依赖图，所有输出元素 cij都可以并发计算。然而，这属于细粒度并行。对于共享内存机器，需要更粗粒度的并行。 

#### 2.1. 粗粒度并行的数据划分 
为了实现粗粒度并行，通常对输出矩阵C进行划分。由于没有数据依赖性，因此不需要同步，这属于“尴尬并行”（embarrassingly parallel）。由于数据结构规则且工作负载已知，因此静态划分相对容易。

有多种方法可以划分矩阵C并分配工作： 

- 一维循环划分 (1D Cyclic Partitioning)：行以循环方式逐个分配给线程，直到所有行都被分配。 
- 一维块划分 (1D Block Partitioning)：行首先被分组到块中，然后每个块分配给一个线程。 
- 一维块循环划分 (1D Block Cyclic Partitioning)：行首先被分组到块中，块的数量远多于线程数量，然后块以循环方式逐个分配给线程。 

在共享内存机器上进行矩阵乘法时，由于没有数据依赖性，可以实现线性加速。重点应放在每个核心上的顺序计算效率上，例如考虑缓存效应、内存层次结构、循环展开和ILP。 
#### 对于A(nxk），B（kxm)和C(nxm)，并且n或m比核数小得多，但k非常大如何设计这种类型的矩阵乘法的并行算法？
```
并行算法设计思路：基于k的分解
由于k非常大，计算Cij=∑Aip×Bpj(p=1到p=k)是一个耗时的操作。我们可以将这个求和过程进行并行化。
核心思想：对内积（点积）进行并行化。
算法步骤设计：
1. 任务划分：
    外层循环（粗粒度）：保留对 C 矩阵的行 i 和列 j 的遍历。由于 n 和 m 较小，这些循环可以在单个线程内部或由少量线程协作完成。
    内层循环（细粒度/并行化点积）：对于每个要计算的 Cij元素，其内部的求和操作∑Aip×Bpj(p=1到p=k) 可以被并行化。
        将 k 维向量的点积操作分解为多个子任务。
        每个子任务计算点积的一部分和。
        最后将所有部分的和累加起来得到最终的 Cij。
2. 并行策略（基于共享内存多核CPU）：
假设我们有P个核心/线程。
方案一：固定分配 Cij元素给线程，并在内部并行化点积
分配策略： 仍按照 C 矩阵的行或列（或块）来分配任务给 P 个线程。
    如果 n≥P 且 m 也相对较大：可以采用之前提到的一维块划分或循环划分，每个线程负责计算 C 矩阵的一部分行或列。
    如果 n<P 或 m<P （即行/列数少于核心数）： 这种情况下，直接按行/列划分会导致大量核心空闲。那么，每个线程可能需要计算多个Cij元素。
关键：并行化内积计算
    对于每个线程负责计算的 Cij元素，其计算Cij=∑Aip×Bpj(p=1到p=k)可以进一步并行化。
    将 k 拆分为 P′个子范围（P′为用于并行化内积的线程数，通常小于等于总线程数 P）。
    每个子线程（或称工作线程）计算 Aip×Bpj乘积的一部分，并累加到自己的局部变量中。
    所有子线程完成后，将各自的局部和累加到Cij的最终值中。这一步需要同步，通常是原子操作或互斥锁来保护Cij的累加。
方案二：动态任务调度（如果 n×m 不够大，但 k 很大）
创建一个任务队列，每个任务就是计算一个 Cij元素。
每个核心从任务队列中领取一个任务，然后计算该Cij元素。
由于 k 很大，计算单个 Cij的工作量足以让一个核心忙碌较长时间，减少了任务分配的开销。
对于每个Cij的计算，仍然可以考虑并行化内积（如方案一所述）。
3. 数据访问模式和局部性优化：
Aip:在计算Cij的时候，会顺序访问 A 的第 i 行。
Bpj:在计算Cij的时候，会顺序访问 B 的第 j 列。
缓存效应：
    A矩阵:由于通常是行主序存储（C/C++）或列主序存储（Fortran），访问 Aip通常是连续的，对缓存友好。
    B矩阵:访问Bpj意味着我们需要按列访问 B 矩阵。如果 B 是行主序存储，这将导致跳跃式访问，对缓存非常不友好。
    优化:在开始计算之前，最好对 B 矩阵进行转置，得到 B^T(mxk)。这样，在计算Cij时，实际上是A的第i行与BT的第j行进行点积，两次访问都变得连续，极大地提高了缓存命中率。这对于k很大的情况尤为关键。
分块（Blocking）：即使在并行化内积时，也要考虑分块，将k维向量的点积分解成若干个小块的点积，每个块大小适合缓存行，以最大化缓存利用率。
4. 同步机制：
    如果方案一中，多个子线程并行计算一个Cij：最终的累加结果需要原子操作（如 std::atomic_fetch_add）或者互斥锁来保护。对于简单的累加，原子操作通常是首选，因为它开销更小。
    如果每个线程独立计算一个或多个Cij：理论上不需要同步，因为输出元素之间没有依赖。但在实际实现中，为了保证所有的Cij都计算完成，可能需要一个屏障（barrier）来同步所有线程，以确保所有计算都已完成，或者在主线程中等待所有工作线程结束。
5. 循环展开和ILP：
在每个核心内部执行点积计算时，仍然可以应用循环展开和向量化（SIMD指令）来提高单个核心的计算效率。由于 k 很大，这些局部优化将带来显著的性能提升。

总结这种特定情况下的并行设计：
当 n 或 m 远小于核心数，但 k 很大时，传统的按行/列划分输出矩阵C的策略效率低下。核心在于将每个Cij元素的内部计算（即 k 维点积）进行并行化。

关键点：
    并行化内积（点积）: 这是利用巨大 k 值进行并行的主要突破口。
    数据局部性优化： 对 B 矩阵进行转置是提高缓存命中率的关键。
    同步： 主要集中在并行化内积的最终累加环节，或用于确保所有任务完成。
```
伪代码示例（简化，以说明并行化内积的核心思想）：
```C++
// 假设 n, m 较小，k 很大，且 num_threads 是核心数
// C[n][m], A[n][k], B[k][m]

// 1. (可选但强烈推荐) 预先转置 B 矩阵，得到 B_T[m][k]
//    B_T[j][p] = B[p][j]

// 伪代码：主循环 (可以由少量线程或单个线程负责迭代 C 的元素)
for (int i = 0; i < n; ++i) {
    for (int j = 0; j < m; ++j) {
        // 计算 C[i][j]
        double sum_C_ij = 0.0;

        // **此处进行内积的并行化**
        // 使用 OpenMP 或 TBB 等并行库
        #pragma omp parallel for reduction(+:sum_C_ij)
        for (int p = 0; p < k; ++p) {
            // 注意：如果 B 未转置，这里访问 B[p][j] 是跳跃访问，效率低
            // 如果 B_T 已转置，这里访问 B_T[j][p] 是连续访问，效率高
            sum_C_ij += A[i][p] * B[p][j]; // 或 A[i][p] * B_T[j][p]
        }
        C[i][j] = sum_C_ij;
    }
}
```

### 3.OpenMP 共享内存编程
OpenMP (Open Multi-Processing) 是一个基于指令的API，用于在共享内存架构上开发并行程序。 

#### 3.1. OpenMP 概述 
- OpenMP是一个高级API，支持C/C++和Fortran编程。
- 它使用预处理器（编译器）指令，即以#pragma开头的命令，内嵌在注释中，指导编译器生成特定类型的代码。例如：#pragma omp construct [clause [clause …]]。
- 它还提供了库函数调用，例如需要包含<omp.h>。
- 通过环境变量进行配置。
- OpenMP旨在简化并行化过程，因为它比Pthread等线程库更容易使用。 
- 它提供了一个小型的API，用更简单的指令隐藏了繁琐的线程调用，从而用相对较少的注解就能并行化顺序程序。 
#### 3.2. 编程者视角下的 OpenMP 
- OpenMP是一个可移植的、多线程的、共享内存的编程规范，语法“轻量”。
- 需要编译器支持 (C, C++ 或 Fortran)。
- OpenMP允许程序员将程序分为串行区域和并行区域，而不是显式创建并发执行的线程。
- 它隐藏了栈管理。
- 提供了一些同步机制。
- OpenMP不会自动并行化，不保证加速比，也不提供数据竞争的自由。
#### 3.3. OpenMP 执行模型：Fork-Join 并行 
- 主（或Master）线程根据需要生成（fork）一个线程组。
- 并行性是逐步添加的，直到达到性能目标，即顺序程序演变为并行程序。
- 在并行区域结束时，线程组会合并（join）回主线程。
#### 3.4. OpenMP 基本代码结构 (C/C++) 
```C
#include <omp.h>
int main() {
    int var1, var2, var3;

    // 串行代码
    // ...

    // 并行区域开始。生成一个线程组。
    // 指定变量作用域
    #pragma omp parallel private(var1, var2) shared(var3)
    {
        // 并行区域由所有线程执行
        // ...

        // 其他OpenMP指令
        // ...

        // 运行时库调用
        // ...
    } // 所有线程加入主线程并解散
    // 恢复串行代码
    // ...
}
```
#### 3.5. OpenMP pragma、函数和子句概念 
- #pragma omp parallel: 并行区域，线程组，结构化块，线程间交错执行。
- int omp_get_thread_num(): 获取当前线程ID。
- int omp_get_num_threads(): 获取当前线程组中的线程数量。
- double omp_get_wtime(): 获取墙钟时间，用于评估代码性能。
- setenv OMP_NUM_THREADS N: 设置默认线程数量的环境变量。
- #pragma omp barrier: 线程同步屏障。
- #pragma omp critical: 临界区，用于保护共享数据免受竞态条件影响。
- #pragma omp for: 循环工作共享，并行执行循环迭代。
- #pragma omp parallel for: parallel 和 for 指令的组合，用于并行化循环。
- reduction(op:list): 对线程组中的值进行归约操作。
- schedule(dynamic [,chunk]), schedule(static [,chunk]): 循环调度方式，影响负载均衡。
- private(list), firstprivate(list), shared(list): 数据环境子句，声明变量的私有或共享属性。
- nowait: 禁用工作共享构造上的隐式屏障。
- #pragma omp single: 指定一个代码块只由一个线程执行。
- #pragma omp task, #pragma omp taskwait: 用于任务并行。
#### 3.6. 并行区域构造 (#pragma omp parallel) 
- 当一个线程遇到parallel指令时，它会创建一个线程组并成为该组的主线程（master thread）。
- 主线程是线程组的成员，其线程ID为0。
- 从并行区域的开始处，所有线程将执行该区域内的相同代码。
- 并行区域的末尾有一个隐式屏障，只有主线程会继续执行此点之后的代码。
##### 3.6.1. 线程数量 
- 线程数量默认由实现决定，通常是CPU或核心的数量。
- 可以使用库函数omp_set_num_threads()设置线程数量。
- 可以使用num_threads子句设置线程数量，例如：#pragma omp parallel num_threads(3)。
- 使用omp_get_num_procs()函数获取节点上可用核心的数量。
- 使用omp_get_num_threads()函数检查创建的线程数量。
- 创建的线程从0（主线程）到nthreads - 1编号。
- 使用omp_get_thread_num()函数获取每个线程的ID。
##### 3.6.2. 共享变量和私有变量 
- 在并行区域外部声明的任何变量都是共享变量。这意味着所有线程引用同一个变量，需要小心使用。
- 在并行区域内部声明的任何变量都是私有变量。每个线程都有自己的变量副本，可以安全使用。
- private(list)子句：将列表中变量声明为每个线程私有。会为线程组中的每个线程声明一个相同类型的新对象。
- shared(list)子句：将列表中变量声明为线程组中所有线程共享。
#### 3.7. Hello World 示例 
顺序程序:
```C
#include <stdio.h>
int main()
{
    printf("hello world\n");
}
```
OpenMP 程序 (简单版):
```C
#include <omp.h> // OpenMP include file
#include <stdio.h>
int main()
{
    #pragma omp parallel { // 并行区域，使用默认线程数
        printf("hello world\n");
    } // 并行区域结束
}
// 编译OpenMP程序使用 -fopenmp 选项: gcc -fopenmp
每个线程都会打印 "hello world"。
```
OpenMP 程序 (带线程ID):
```C
#include <omp.h>
#include <stdio.h>
int main()
{
    #pragma omp parallel // 并行区域，使用默认线程数
    {
        int tid; // 局部变量，每个线程拥有自己的副本
        tid = omp_get_thread_num(); // 每个线程获取自己的ID
        printf("Hello World from thread = %d\n", tid);
    } // 并行区域结束
}
```
OpenMP 程序 (私有化 tid 变量):
```C
#include <omp.h>
#include <stdio.h>
int main()
{
    int tid; // tid 在并行区域外部声明
    #pragma omp parallel private(tid) // tid 现在是局部变量
    {
        tid = omp_get_thread_num();
        printf("Hello World from thread = %d\n", tid);
    }
}
```
#### 3.8. 工作共享构造：for 指令 
- #pragma omp for [clause ...] newline
- for 指令指定其后的循环迭代必须由线程组并行执行。
- for 指令必须在并行区域内部。
- 循环控制索引 i 默认对每个线程都是“私有”的。 
- 在并行 for 循环结束时，线程会等待直到所有线程都完成循环，然后才能继续执行循环之后的代码。 

示例:
```C
#pragma omp parallel
{
    #pragma omp for
    for (i=0; i<N; i++){
        c(i);
    }
}
```
OpenMP 快捷方式：parallel 和 for 指令合并 

以下两种写法是等价的：
```C
double res[MAX];
int i;
#pragma omp parallel
{
    #pragma omp for
    for (i=0; i< MAX; i++) {
        res[i] = huge();
    }
}

// 等价于
double res[MAX];
int i;
#pragma omp parallel for
for (i=0; i< MAX; i++) {
    res[i] = huge();
}
```
工作分配默认是块划分 (Block partition)。 
#### 3.9. 处理循环 
- 找到计算密集型循环。
- 使循环迭代独立，以便它们可以安全地以任何顺序执行，而没有循环携带依赖 (loop-carried dependencies)。
- 放置适当的OpenMP指令并进行测试。

#### 示例：移除循环携带依赖 
原始代码 (有依赖):
```C
int i, j, A[MAX];
j = 5;
for (i=0;i< MAX; i++) {
    j +=2;
    A[i] = big(j);
}
```
并行化后的代码 (移除依赖):
```C
int i, A[MAX];
#pragma omp parallel for
for (i=0;i< MAX; i++) {
    int j = 5 + 2*(i+1); // 移除了循环携带依赖
    A[i] = big(j);
}
// 注意：循环索引 "i" 默认是私有的。
```
#### 3.10. 矩阵-向量乘法示例 
顺序例程:
```C
int i, k;
for (i = 0; i < m; i++)
    for (k = 0; k < n; k++)
        b[i] += A[i][k] * x[k]; // 假设 b 已经初始化
```
#### 并行化 i 循环: 
- 并行化 k 循环会导致循环携带依赖。
- 可以并行化 k 循环，但会更复杂。
- 因此，通常并行化 i 循环：
```C
int i, k;
#pragma omp parallel for shared (A, x, b) private (i, k)
for (i = 0; i < m; i++)
    for (k = 0; k < n; k++)
        b[i] += A[i][k] * x[k]; // 假设 b 已经初始化
```
#### 3.11. 性能评估 
- 使用 omp_get_wtime() 函数评估代码性能。
- omp_get_wtime() 是一个可移植的墙钟计时例程，返回自某个过去时间点以来经过的秒数（双精度浮点值）。
通常成对使用，将第一次调用的值从第二次调用的值中减去，以获得代码块的执行时间。