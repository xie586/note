## HPC-AI Foundation
###  HPC 基础知识回顾
- 并行计算：讲解并行计算的基本原理，如任务分解、数据并行和模型并行等。
- 集群架构：介绍 HPC 集群的构成，包括计算节点、互联网络（如 InfiniBand）和存储系统（如 Lustre, GPFS）。
- 调度系统：讲解 SLURM、PBS 等作业调度系统的使用，包括如何提交、监控和管理计算任务。
- 性能度量：解释 MFLOPS、TFLOPS 等性能指标，以及如何评估 HPC 应用的性能。

### AI 基础知识回顾
- 机器学习与深度学习：区分机器学习和深度学习，并介绍常见的算法和模型，如卷积神经网络 (CNN)、循环神经网络 (RNN) 和变换器 (Transformer)。
- AI 框架：重点介绍主流的深度学习框架，如 TensorFlow 和 PyTorch。讲解它们的基本用法、模型构建、训练流程以及如何利用 GPU 进行加速。
- 数据处理：强调数据预处理、特征工程和数据增强在 AI 训练中的重要性。
###  HPC 与 AI 的融合：HPC-AI Convergence
- 为什么融合？ 
讲解 AI 模型（特别是深度学习模型）的复杂性和庞大数据量对计算资源的需求，传统单机或小规模计算难以满足，因此需要 HPC 的强大算力支撑。同时，HPC 也可以从 AI 中受益，例如通过 AI 优化科学模拟参数或加速数据分析。

- 并行 AI 训练：
1. 数据并行：详细解释如何将大规模数据集分散到多个计算节点上进行训练，每个节点处理数据子集，并通过 AllReduce 等集体通信操作同步模型参数。

2. 模型并行：讲解当模型过大无法放入单个 GPU 内存时，如何将模型不同层或部分放置在不同 GPU 上进行计算。

3. 混合并行：结合数据并行和模型并行，以应对超大规模模型和数据集。

4. 分布式训练框架：讲解如何在 HPC 环境中有效地使用 TensorFlow Distributed、PyTorch DistributedDataParallel 等分布式训练工具。这包括设置环境变量、启动分布式进程以及处理通信开销。

5. 容器化技术：介绍 Docker 和 Singularity (Apptainer) 等容器化技术在 HPC-AI 中的应用，如何打包 AI 环境，确保在不同集群上的可移植性和可重复性。

###  优化 HPC-AI 应用性能
#### 什么是MPI (What is MPI)
1. 定义：MPI是一个标准化、可移植的消息传递系统，旨在在各种并行计算架构上运行。它使进程能够通过发送和接收消息进行相互通信，使其适用于分布式内存系统。

2. 主要特性：
- 可移植性：在各种并行计算平台上运行。
- 性能：专为高效率和可扩展性设计。
- 语言支持：提供对 C、C++ 和 Fortran 的绑定。

3. 基本概念：
- 进程：具有独立内存空间的独立执行单元。
- 通信器：定义可以进行通信的进程组。
- 秩：通信器内进程的唯一标识符。

#### MPI 通信范式
1. 点对点通信：
- 阻塞操作：MPI_Send, MPI_Recv
- 非阻塞操作：MPI_Isend, MPI_Irecv
- 用于进程对之间的直接通信。
2. 集合通信：
- 涉及一组进程的操作。
- 例子包括：

    广播：MPI_Bcast

    收集/分散：MPI_Gather, MPI_Scatter

    归约：MPI_Reduce, MPI_Allreduce

3. 单边通信（在 MPI-2 中引入）：
- 允许进程指定发送和接收数据的所有通信参数。
- 函数包括：MPI_Put, MPI_Get。

#### 什么是 PGAS
- 定义：

PGAS 是一种并行编程模型，它提供了一个全局内存地址空间，该空间在所有进程之间逻辑上进行了分区。

每个进程对共享内存的一部分具有亲和性，从而能够进行本地和远程内存访问。

- 关键特性：

 结合了共享内存编程的简易性与消息传递的性能。

 支持单边通信，允许一个进程在没有远程进程主动参与的情况下读写远程内存。
- 常见的 PGAS 语言和库：
```
Unified Parallel C (UPC)
Coarray Fortran (CAF)
Chapel
X10
OpenSHMEM
```
#### PGAS 编程模型
1. 基于语言的 PGAS 模型：
- Unified Parallel C (UPC)：ISO C 的扩展，用于并行计算，具有共享和私有内存空间。
- Coarray Fortran (CAF)：Fortran 扩展，支持使用 Coarray 的 SPMD 并行。
- Chapel：为并行性和局部性设计的高生产力语言。
- X10：由 IBM 开发的语言，强调异步性和局部性。

2. 基于库的 PGAS 模型：
- OpenSHMEM：提供一组用于远程内存访问和同步的 API。
- Global Arrays：提供分布式数组的全局视图，实现共享内存风格的编程。
3. 特性：
- SPMD 模型：单一程序，多数据执行模型。
- 数据局部性感知：程序员可以优化数据局部性以提高性能。
- 可扩展性：适用于大规模 HPC 系统。
#### 什么是共享内存模型？
- 定义：

在共享内存模型中，多个处理器或线程访问一个共同的内存空间。

每个处理器可以直接读写共享变量，从而促进通信和协调。

- 关键特性：
```
全局地址空间：所有线程共享相同的内存地址空间。
隐式通信：数据交换通过共享变量发生，无需显式消息传递。
基于线程的并行：通常使用单个进程内的线程来实现。
```
- 常见架构：

对称多处理 (SMP)：所有处理器对内存的访问权限相同。

非统一内存访问 (NUMA)：内存访问时间因内存位置相对于处理器的远近而异。

- 编程模型：

OpenMP：用于 C、C++ 和 Fortran 的基于指令的并行化。

POSIX 线程 (Pthreads)：针对 C/C++ 的低级线程 API。
#### 共享内存编程中的挑战
1. 同步问题：
- 竞态条件：当多个线程并发地访问和修改共享数据时发生。
- 死锁：当线程无限期等待彼此持有的资源时产生。
2. 可伸缩性限制：
- 由于对共享资源的争用，随着线程数量的增加，性能可能会下降。
3. 内存一致性：
- 确保所有线程对内存具有一致的视图可能很复杂，尤其是在弱内存模型系统上。
4. 调试困难：
- 与并发相关的错误通常是非确定性的，难以重现。
5. 最佳实践：
- 明智地使用同步原语（例如，互斥锁、屏障）。
- 尽可能减少共享数据访问。
- 采用线程安全编程技术。

#### OpenMP 编程
- OpenMP 概述：

OpenMP 是一个广泛使用的 API，用于 C、C++ 和 Fortran 中的共享内存并行编程。

它使用编译器指令来指定并行区域和工作共享构造。

- OpenMP 基本构造：
```c
#pragma omp parallel：定义一个并行区域。
#pragma omp for：将循环迭代分配给线程。
#pragma omp critical：定义一个临界区以防止竞态条件。
```

#### HPC 中的混合编程
- 定义：
混合编程结合了多种并行编程模型，以更好地利用现代异构 HPC 架构。

- 为什么要混合编程？

许多 HPC 系统是多核节点的集群（例如，数千个节点 × 每个节点几十个核心）。

高效利用以下方面：
```
MPI 用于节点间（分布式内存）
OpenMP 或线程用于节点内（共享内存）
CUDA/OpenACC 用于加速器（如 GPU）
```
- 常见混合模型：
```
MPI + OpenMP – CPU 多核集群
MPI + Pthreads – 细粒度线程控制
MPI + CUDA/OpenACC – CPU+GPU 集群
MPI + PGAS – 节点内 PGAS，节点间 MPI
```

#### 混合模型中的挑战与最佳实践

- 挑战：
```
组合的模型数量越多，复杂性越高。
必须将并行性与硬件拓扑相匹配。
调试和性能分析变得更加困难。
MPI 中的线程安全（特别是 MPI_THREAD_MULTIPLE）可能成为一个问题。
```
- 最佳实践：
```
使用粗粒度 MPI + 细粒度 OpenMP。
考虑“每个 NUMA 域一个 MPI 进程”模型。
避免过度订阅（不要生成比硬件核心更多的线程）。
基准测试不同配置（MPI 进程数与线程数）。
```
- 实践中的例子：
气候模型、流体动力学、深度学习框架通常使用混合设计。

### 三大主要应用类别

1. 科学计算
- 消息传递接口 (MPI)，包括 MPI + OpenMP，是主导的编程模型。
- 关于分区全局地址空间 (PGAS) 的讨论很多。
- UPC, OpenSHMEM, CAF 等。
- 混合编程：MPI + PGAS (OpenSHMEM, UPC)。

2. 大数据/企业/商业计算
- 侧重于大数据和数据分析。
- Hadoop (HDFS, HBase, MapReduce)。
- Spark 正在兴起，用于内存计算。
- Memcached 也用于 Web 2.0。

3. 人工智能（统计）计算
- 消息传递编程模型（不使用 MPI 标准！）
- 向 PGAS 迈进（用于单边通信）。

### 统一计算设备架构 (CUDA)
CUDA 是 NVIDIA 的并行计算平台和编程模型，使开发人员能够利用 GPU 的大规模计算能力（大规模并行）。
- 关键概念：
数千个线程：为细粒度并行设计。GPU 同时运行许多线程。
- SIMT 执行模型：
线程被分组到 warps 中，以锁步方式执行（单指令，多线程）。
- 分层内存：
```
全局内存：所有线程都可访问。
共享内存：快速的，每个块的内存。
本地内存：每个线程私有的。
```
- 编程语言：
主要使用带扩展的 C/C++，通过包装器支持 Python、Fortran 和其他语言。
#### CUDA 编程模型是什么？
基本编程模型是共享内存。但不是严格意义上的 pthreads。B200 NVL72 正在将我们带向 PGAS。来自不同 OS 域的 GPU 共享内存空间。