## 优化方法以及原理
1. Ofast优化
- 原理：Ofast是编译器（如GCC 、G++）的优化选项。它启用激进的优化策略，在不违反语言标准主要规则前提下，开启一些可能牺牲标准合规性（如放宽浮点数计算规则 ）的优化。例如，允许编译器对浮点数运算进行重新排序、假设某些数学特性等，以减少计算指令周期，从而提高程序运行速度。
- 效果：能显著提升程序在浮点运算密集型任务（如矩阵乘法 ）中的执行效率，减少运行时间。但可能导致程序在某些严格遵循标准的场景下出现细微差异（如浮点数运算结果的微小偏差 ），不过在多数科学计算和数值模拟场景中可接受。
 
2. matmul_Ofast_openmp 
- 原理：在Ofast优化基础上，引入OpenMP（Open Multi-Processing）。OpenMP是一种共享内存并行编程模型，通过在代码中添加简单的编译制导语句（如#pragma omp parallel for），指示编译器将循环等代码段并行化。在矩阵乘法中，可将矩阵元素的计算循环并行分配到多个线程上，利用多核CPU资源同时计算不同部分，加快整体运算速度。
- 效果：充分利用多核CPU优势，大幅提升矩阵乘法运算速度，尤其对于大规模矩阵，性能提升明显。且编程模型简单，只需对代码做少量修改即可实现并行加速。
 
3.  matmul_Ofast_openmp_block 
- 原理：基于matmul_Ofast_openmp，采用分块（blocking ）技术。矩阵乘法中，将大矩阵划分成小的子矩阵块（如按固定大小的行和列划分 ）。计算时，每次处理一个子矩阵块的乘法，使数据在缓存中停留时间更长，减少数据从主存到缓存的频繁读取，提高缓存命中率。结合OpenMP并行计算这些子矩阵块，进一步提升性能。
- 效果：有效降低内存访问开销，减少因缓存不命中导致的性能瓶颈，在大规模矩阵乘法中，相比未分块的并行计算，性能有显著提升，尤其在内存带宽受限的场景下优势明显。
 
4.  matmul_Ofast_openmp_block_avx 
- 原理：在matmul_Ofast_openmp_block基础上，利用AVX（Advanced Vector Extensions）指令集。AVX是一种单指令多数据（SIMD）指令集，可让CPU一次处理多个数据（如一次处理多个浮点数）。在矩阵乘法中，对矩阵元素的向量运算（如矩阵行或列向量的乘法 ）可利用AVX指令集并行处理多个元素，配合分块和OpenMP并行计算，极大提升运算效率。
- 效果：大幅提升向量运算效率，进一步加快矩阵乘法计算速度，尤其在支持AVX指令集的现代CPU上，对于大规模矩阵的乘法运算，性能提升显著，可充分发挥硬件的并行计算能力。
 
5.  matmul_Ofast_openmp_block_mkl 
- 原理：借助英特尔数学核心函数库（Intel Math Kernel Library，MKL ）。MKL集成大量针对数学运算（包括矩阵运算 ）高度优化的函数，如矩阵乘法、矩阵分解等。在矩阵乘法实现中，调用MKL库中优化的矩阵乘法函数（如cblas_dgemm等），结合之前的Ofast、OpenMP并行、分块等优化策略，利用MKL库在底层对不同CPU架构的深度优化（如针对英特尔CPU的微架构优化），进一步提升性能。
- 效果：利用MKL库的高效实现，在矩阵乘法性能上有极大提升，尤其在处理大规模、复杂矩阵运算时，相比自行编写的基础实现，能大幅减少计算时间，提高计算效率，且代码更简洁、健壮。

6.  matmul_Ofast_openmp_block_openblas 
- 原理：结合OpenBLAS库，OpenBLAS是一个优化的BLAS（Basic Linear Algebra Subprograms，基本线性代数子程序）实现。它提供了高效的矩阵向量运算等基本线性代数操作函数。在矩阵乘法中，使用OpenBLAS库中优化的函数实现矩阵乘法的核心计算部分，同时结合Ofast优化、OpenMP并行、分块技术等，利用OpenBLAS对不同硬件平台的优化（如针对不同CPU架构的汇编级优化），实现对矩阵乘法性能的优化。
- 效果：利用OpenBLAS库的高效性，在矩阵乘法运算上实现性能提升，且OpenBLAS是开源库，具有良好的跨平台性和可扩展性，能为矩阵乘法运算提供稳定且高效的计算支持，适用于多种硬件环境和应用场景。